{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydTsfITlhbn1"
   },
   "source": [
    "# 3.6 手書き数字認識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "HOME='/home/jovyan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjMl5PnefwK6"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/work/\n",
    "# !git clone https://github.com/oreilly-japan/deep-learning-from-scratch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IREB4Wc_gSVm",
    "outputId": "10dfca41-aaff-4220-933e-041030ed600b"
   },
   "outputs": [],
   "source": [
    "# %cd /content/drive/MyDrive/work/deep-learning-from-scratch/ch03/\n",
    "base_path=HOME + '/work/DL_scratch/' + 'deep-learning-from-scratch/ch03'\n",
    "%cd $base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZB7YCzZhT0h"
   },
   "source": [
    "## 3.6.1. MNISTデータセット\n",
    "\n",
    "- 訓練画像が60000枚\n",
    "- テスト画像がが10000枚\n",
    "- 0から9までの数字画像から構成されている\n",
    "- 28x28のグレー画像(1chのみ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6j9fWxo5hG8F",
    "outputId": "d44db386-5d79-48c9-b028-26aab021ce6a"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "# load_mnistは以下の形式でMNISTデータを返す\n",
    "# (訓練画像, 訓練ラベル), (テスト画像, テストラベル)\n",
    "# arg (normalize): 正規化\n",
    "# arg (flatten): 画像を平滑化する(1次元配列にする)\n",
    "# \n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "    flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "q7OouvhflXks",
    "outputId": "a6465633-2321-4fd2-dba3-349241467b39"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(\n",
    "    flatten=True, normalize=False\n",
    ")\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)\n",
    "\n",
    "print(img.shape)\n",
    "img = img.reshape(28, 28)   # 平滑化したデータを元画像(28x28)に変形\n",
    "print(img.shape)\n",
    "\n",
    "# img_show(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_63psT2qVMo"
   },
   "source": [
    "## 3.6.2 ニューラルネットワークの推論処理\n",
    "\n",
    "MNISTの推論処理を行うニューラルネットは以下のニューロン数で構成される\n",
    "\n",
    "- 入力層: 784個\n",
    "- 出力層: 10個\n",
    "- 隠れ層1: 50個\n",
    "- 隠れ層2: 100個\n",
    "\n",
    "- ここで入出力層のニューロン数は以下と対応する\n",
    "    - 入力層: 入力画像サイズのピクセル数(28x28=784)\n",
    "    - 出力層: クラス分類の個数(MNISTはは0~9となる10種類の数字)\n",
    "\n",
    "- 隠れ層のニューロン数は任意の個数に設定できる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQAYxKI9oP4W"
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.pardir)\n",
    "import pickle\n",
    "\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import softmax, sigmoid\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open('sample_weight.pkl', 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    print(f'W2: {W2.shape}')\n",
    "    print(f'W3: {W3.shape}')\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "id": "WMCG37uVveqc",
    "outputId": "ae78abd0-700d-48c5-e9b8-087e53be0a51"
   },
   "outputs": [],
   "source": [
    "# MNISTデータセットの取得\n",
    "x, t = get_data()\n",
    "# モデルの定義\n",
    "network = init_network()\n",
    "accuracy_cnt = 0\n",
    "\n",
    "# 推論の実行\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "\n",
    "    print(f'y: {y}')\n",
    "\n",
    "    p = np.argmax(y)    # 最も確率の高い要素ののidxを取得\n",
    "    print(f'p: {p}')\n",
    "\n",
    "\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "    img = x[i]\n",
    "    img = img.reshape(28, 28)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb1-iTKTf2gQ"
   },
   "source": [
    "## 正規化と前処理\n",
    "\n",
    "- データをある決まった範囲に変換する処理を正規化(normalize)と呼ぶ\n",
    "\n",
    "- NNの入力データに対して何らかの決まった変換を行うことを前処理(pre-processing)と呼ぶ\n",
    "\n",
    "- 前処理ははNNにおいて実践的によく用いられる\n",
    "- 前処理の有効性は識別性能の向上が学習の高速化など多くの実験によって示されている\n",
    "\n",
    "- 上記, MNISTの例では「前処理としてデータ全体の値をを255で割る」単純な正規化を行なった\n",
    "\n",
    "- 実際の前処理では、データ全体の分布を考慮して前処理を行うことが多い\n",
    "\n",
    "- たとえば, データ全体の平均や標準偏差を利用する前処理\n",
    "- データ全体がが0を中心に分布するように移動させる\n",
    "- データの広がりをある範囲に収める\n",
    "\n",
    "- データ全体の分布の形状を均一にする白色化(whitening)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sstPenR1igs0"
   },
   "source": [
    "## 3.6.3. バッチ処理\n",
    "\n",
    "ニューラルネットの各層の重みの形状を出力してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VawFq11Jf5ED",
    "outputId": "d477f48f-e960-4285-d37d-b3b52d70b607"
   },
   "outputs": [],
   "source": [
    "x, _ = get_data()\n",
    "network = init_network()\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "print('x.shape: ', x.shape)\n",
    "print('x[0].shape: ', x[0].shape)\n",
    "print('W1.shape: ', W1.shape)\n",
    "print('W2.shape: ', W2.shape)\n",
    "print('W3.shape: ', W3.shape)\n",
    "\n",
    "y = predict(network, x[0])\n",
    "print('y.shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQgU6FS5kB16"
   },
   "source": [
    "- 784の要素からなる1次元配列が入力されている: -> x[0].shape\n",
    "- 1次元の配列が出力されている: -> W3.shape\n",
    "\n",
    "- 100枚の画像をまとめて1回のpredict()で処理することを考える\n",
    "- これには, xの形状をを100x784として, 100枚分のデータをまとめて入力すればよい.\n",
    "\n",
    "- その場合, 入出力データの形状は以下のようになる\n",
    "    - 入力データ形状: 100x784(入力データ個数, ピクセル数)\n",
    "    - 出力データ形状: 100x10(入力データ個数 * 出力クラス数)\n",
    "\n",
    "- 出力データは以下のような形で格納されることになる\n",
    "    - x[0...n]: 0からn番目の画像データ\n",
    "    - y[0...n]: 0からn番目の画像の推論結果\n",
    "\n",
    "- まとまりのある入力データを**バッチ(batch)**と呼ぶ\n",
    "- batchには**束**という意味があり, 画像がお札のように束になっているイメージで考えるとよい\n",
    "\n",
    "- バッチ処理にはコンピュータで計算する上で大きな利点がある\n",
    "    - バッチ処理によって, 1枚あたりの処理時間を大幅に短縮できる\n",
    "    - これは数値計算ライブラリが大きな配列の計算を効率よく処理できるように最適化が行われていることに起因する\n",
    "    - NNの計算において, データ転送がボトルネックになる場合はバッチ処理を行うことでバス帯域の負荷を軽減できる\n",
    "    - **大きな配列を一度に計算する方が、分割した小さい配列を逐次処理するより速く計算できる**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GX-hqAnhjXLl",
    "outputId": "637bae2f-de9c-4350-ce3e-2008a31396f7"
   },
   "outputs": [],
   "source": [
    "## バッチ処理の実装\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # バッチの数\n",
    "accuracy_cnt = 0\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print('Accuracy:' + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv9C65cmrrAk"
   },
   "source": [
    "解説はあとで読む\n",
    "\n",
    "- range()\n",
    "- argmax()で最大値ののindexを取得するする\n",
    "    - axis=1を指定と1次元目の要素毎に最大値のindexを見つけることを指定している\n",
    "    - \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chpater3-6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
