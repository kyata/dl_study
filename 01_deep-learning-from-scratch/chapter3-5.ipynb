{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1652602532179,
     "user": {
      "displayName": "Yuki Katayama",
      "userId": "15528639115256770261"
     },
     "user_tz": -540
    },
    "id": "g6fEJa0qpDqg"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "HOME='/home/jovyan/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtkfkYKl4ibI"
   },
   "source": [
    "# 3.5 出力層の設計\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCCoNZoj5vFl"
   },
   "source": [
    "- NNは分類問題と回帰問題の両方に用いることができる\n",
    "- 分類と回帰のどちらに用いるかで、出力層の活性化関数を変更する必要がある\n",
    "    - 一般的に回帰問題では恒等関数を\n",
    "    - 分類問題ではソフトマックス関数を用いる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml7I98y65UE1"
   },
   "source": [
    "# 3.5.1. ソフトマックス関数の定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ソフトマックス関数は次の式で表すことができる\n",
    "\n",
    "$$\n",
    "    y_{k} = \\frac{exp(a_{k})}{\\sum_{i=1}^{n} exp(a_{i})}\n",
    "$$\n",
    "\n",
    "- n: 出力層の個数\n",
    "- ソフトマックス関数の分子は入力信号$ ak $の指数関数\n",
    "- 分母は全ての入力信号の指数関数の和\n",
    "\n",
    "- ソフトマックスの出力はすべての入力信号から影響を受ける\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数の実装(準備)\n",
    "a = np.array([.3, 2.9, 4.])\n",
    "exp_a = np.exp(a)\n",
    "print(f'exp_a: {exp_a}')\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(f'sum_exp_a: {sum_exp_a}')\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(f'y: {y}')\n",
    "print(f'sum_y: {np.sum(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数の実装(オーバーフロー対策前)\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- コンピュータでの計算は、オーバーフロー等を起こす問題がある\n",
    "- ソフトマックス関数の実装では指数関数の計算があるが、**それは容易に大きな値になる**\n",
    "- 大きな値どうしてで割り算を行うと, 数値が\"不安定\"な結果となってしまう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1010, 1000, 990])\n",
    "np.exp(a) / np.sum(np.exp(a))    # => 正しく計算されない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ソフトマックスの指数関数の計算を行う際に、**定数を加減算しても、結果は変わらない**\n",
    "- オーバーフロー対策としては**入力信号の中で最大の値を用いることが一般的**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.max(a)\n",
    "print(f'a-c: {a-c}')\n",
    "\n",
    "print(np.exp(a-c) / np.sum(np.exp(a-c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ソフトマックス関数の実装(オーバーフロー対策後)\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    \n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.3. ソフトマックス関数の特徴\n",
    "\n",
    "- ソフトマックス関数の出力は0から1.0の実数になる\n",
    "- ソフトマックス関数の出力の総和は1になる\n",
    "\n",
    "- 上記の特徴から, **ソフトマックス関数の出力を確率として解釈することができる**\n",
    "- ソフトマックス関数を用いることで、**問題に対して確率的(統計的)な対応ができるようになる**\n",
    "\n",
    "### 注意点 \n",
    "- ソフトマックス関数を適用しても各要素の大小関係は変わらない\n",
    "    - 指数関数$ (y=exp(x)) $が単調増加する関数であることに起因\n",
    "\n",
    "- NNのクラス分類では, 一般的に出力の一番大きいニューロンに相当するクラスだけを認識結果とする(ことが多い)\n",
    "- ソフトマックス関数を適用しても出力の一番大きいニューロンの場所は変わらない\n",
    "- そのため, NNが運類を行う際には出力層のソフトマックス関数を省略することができる\n",
    "    - 指数関数の計算は計算機にとって重い処理となるため, **出力層のソフトマックス関数は省略するのが一般的**\n",
    "    - 推論フェーズでは出力層のソフトマックス関数は省略するのが一般的らしい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.4. 出力層のニューロンの数\n",
    "\n",
    "- 出力層のニューロンの数は、**解くべき問題に応じて適宜決める必要がある**\n",
    "    - クラス分類を行う問題では、出力層のニューロンの数は分類したいクラスの数に設定するのが一般的\n",
    "    - e.g.) 10クラスを識別したい問題なら, **出力層のニューロンの数は10個に設定する**\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgoy5PpZeN/Ou4Hrd17SiW",
   "name": "chpater3-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
