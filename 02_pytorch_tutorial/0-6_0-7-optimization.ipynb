{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67101c6-bf4f-4647-a830-a959a62e6efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-katayama/notebooks', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/y-katayama/venv/pt1.7/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# importディレクトリの追加\n",
    "# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "print(sys.path)\n",
    "\n",
    "# プロキシの設定\n",
    "# os.environ['HTTP_PROXY'] = ''\n",
    "# os.environ['HTTPS_PROXY'] = ''\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b221e63-1a66-4da5-8964-2dedabf6108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  6 16:04:40 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   32C    P8    17W / 184W |   1076MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 40%   30C    P8    14W / 184W |      8MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1986      G   /usr/lib/xorg/Xorg                 45MiB |\n",
      "|    0   N/A  N/A      2921      C   ...ma/venv/pt1.7/bin/python3     1026MiB |\n",
      "|    1   N/A  N/A      1986      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35731b84-112a-4bb3-8976-5bcb61ac7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.1%/home/y-katayama/venv/pt1.7/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c458616-251c-4cd4-af1e-04eac64bb097",
   "metadata": {},
   "source": [
    "# 最適化ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b5ed49d-aeae-4e82-90a4-33db6de924ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40cbd17-fefc-4406-8cf9-9534d9b2fae8",
   "metadata": {},
   "source": [
    "- 最適化ループの1回のイテレーションは, エポックと呼ばれる\n",
    "- 各エポックは2種類のループから構成される\n",
    "\n",
    "  - 訓練ループ\n",
    "  - 検証/テストループ\n",
    "  \n",
    "## 損失関数: Loss function\n",
    "\n",
    "- 損失関数はモデルが推論した結果と, 実際の正解の誤差の大きさを測定する関数\n",
    "- 損失を計算するためには, 入力データに対するモデルの推論結果を求めて, その値と正解ラベルとの違いを比較する\n",
    "\n",
    "- 一般的な損失関数は回帰: `nn.MSELoss(Mean Square Error)`, 分類: `nn.NLLoss(Negative Log Likelihood)`が使用される\n",
    "- `nn.CrossEntropyLoss`は`nn.LogSoftmax`と`nn.NLLLoss`を結合した損失関数\n",
    "- モデルが出力するlogit値を`nn.CrossEntropyLoss()`に与えて正規化し, 予測誤差を求める\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e8d27d-c7fe-4c15-ad9d-66a2eb91ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f62469-02b6-45cb-863b-e1ceeb0ba31c",
   "metadata": {},
   "source": [
    "## 最適化アルゴリズム\n",
    "\n",
    "- 最適化アルゴの詳細については省略\n",
    "- https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "- 訓練ループ内ではoptimizerは以下のように動作する\n",
    "\n",
    "  1. `optimizer.zero_grad()`を実行し, モデルパラメータの勾配をリセットする\n",
    "  2. `loss.backwards()`を実行し, backpropを行う\n",
    "  3. optimizer.step()を実行し, 各パラメータの勾配を使用してパラメータの値を調整する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "447c85be-2609-40c6-ab34-0ef66f386412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):        \n",
    "        \n",
    "        # 推論と損失の計算\n",
    "        \n",
    "        ## モデルからロジットを求める\n",
    "        pred = model(X)\n",
    "        \n",
    "        ## ロジットと正解ラベルを損失関数に与えて, 損失値(スカラ―)を得る\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        ## 勾配をリセット\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## backpropで損失関数に対する勾配を求める\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 勾配を使用して, パラメータの値を調整\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69831b9e-669c-4e9c-a837-041fd4bbe8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306533  [    0/60000]\n",
      "loss: 2.300227  [ 6400/60000]\n",
      "loss: 2.281330  [12800/60000]\n",
      "loss: 2.275303  [19200/60000]\n",
      "loss: 2.260060  [25600/60000]\n",
      "loss: 2.252860  [32000/60000]\n",
      "loss: 2.260581  [38400/60000]\n",
      "loss: 2.235570  [44800/60000]\n",
      "loss: 2.233417  [51200/60000]\n",
      "loss: 2.219148  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 0.034661 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.222991  [    0/60000]\n",
      "loss: 2.204427  [ 6400/60000]\n",
      "loss: 2.167656  [12800/60000]\n",
      "loss: 2.177789  [19200/60000]\n",
      "loss: 2.119698  [25600/60000]\n",
      "loss: 2.126154  [32000/60000]\n",
      "loss: 2.142106  [38400/60000]\n",
      "loss: 2.097288  [44800/60000]\n",
      "loss: 2.094998  [51200/60000]\n",
      "loss: 2.068624  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 0.032227 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.091789  [    0/60000]\n",
      "loss: 2.043935  [ 6400/60000]\n",
      "loss: 1.977867  [12800/60000]\n",
      "loss: 2.002035  [19200/60000]\n",
      "loss: 1.888289  [25600/60000]\n",
      "loss: 1.923173  [32000/60000]\n",
      "loss: 1.945532  [38400/60000]\n",
      "loss: 1.881698  [44800/60000]\n",
      "loss: 1.883080  [51200/60000]\n",
      "loss: 1.840274  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.028645 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.906094  [    0/60000]\n",
      "loss: 1.820437  [ 6400/60000]\n",
      "loss: 1.730741  [12800/60000]\n",
      "loss: 1.765530  [19200/60000]\n",
      "loss: 1.617180  [25600/60000]\n",
      "loss: 1.700521  [32000/60000]\n",
      "loss: 1.715552  [38400/60000]\n",
      "loss: 1.667599  [44800/60000]\n",
      "loss: 1.659375  [51200/60000]\n",
      "loss: 1.604106  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.025228 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.723227  [    0/60000]\n",
      "loss: 1.618790  [ 6400/60000]\n",
      "loss: 1.521840  [12800/60000]\n",
      "loss: 1.564272  [19200/60000]\n",
      "loss: 1.399891  [25600/60000]\n",
      "loss: 1.527066  [32000/60000]\n",
      "loss: 1.519457  [38400/60000]\n",
      "loss: 1.510973  [44800/60000]\n",
      "loss: 1.481908  [51200/60000]\n",
      "loss: 1.430312  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.4%, Avg loss: 0.022662 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.569565  [    0/60000]\n",
      "loss: 1.468586  [ 6400/60000]\n",
      "loss: 1.361634  [12800/60000]\n",
      "loss: 1.423246  [19200/60000]\n",
      "loss: 1.241925  [25600/60000]\n",
      "loss: 1.397813  [32000/60000]\n",
      "loss: 1.378300  [38400/60000]\n",
      "loss: 1.397754  [44800/60000]\n",
      "loss: 1.352812  [51200/60000]\n",
      "loss: 1.316364  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 0.020807 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.450067  [    0/60000]\n",
      "loss: 1.361375  [ 6400/60000]\n",
      "loss: 1.239841  [12800/60000]\n",
      "loss: 1.322408  [19200/60000]\n",
      "loss: 1.132704  [25600/60000]\n",
      "loss: 1.301529  [32000/60000]\n",
      "loss: 1.280854  [38400/60000]\n",
      "loss: 1.315972  [44800/60000]\n",
      "loss: 1.260347  [51200/60000]\n",
      "loss: 1.243177  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.019490 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.361627  [    0/60000]\n",
      "loss: 1.285990  [ 6400/60000]\n",
      "loss: 1.148686  [12800/60000]\n",
      "loss: 1.248079  [19200/60000]\n",
      "loss: 1.058755  [25600/60000]\n",
      "loss: 1.230606  [32000/60000]\n",
      "loss: 1.214367  [38400/60000]\n",
      "loss: 1.255913  [44800/60000]\n",
      "loss: 1.193951  [51200/60000]\n",
      "loss: 1.194329  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.018552 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.295632  [    0/60000]\n",
      "loss: 1.232500  [ 6400/60000]\n",
      "loss: 1.080697  [12800/60000]\n",
      "loss: 1.192225  [19200/60000]\n",
      "loss: 1.007857  [25600/60000]\n",
      "loss: 1.177017  [32000/60000]\n",
      "loss: 1.167689  [38400/60000]\n",
      "loss: 1.213829  [44800/60000]\n",
      "loss: 1.144378  [51200/60000]\n",
      "loss: 1.159284  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.3%, Avg loss: 0.017866 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.244344  [    0/60000]\n",
      "loss: 1.192464  [ 6400/60000]\n",
      "loss: 1.028730  [12800/60000]\n",
      "loss: 1.146703  [19200/60000]\n",
      "loss: 0.970423  [25600/60000]\n",
      "loss: 1.135446  [32000/60000]\n",
      "loss: 1.132638  [38400/60000]\n",
      "loss: 1.182732  [44800/60000]\n",
      "loss: 1.105569  [51200/60000]\n",
      "loss: 1.133718  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.017339 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a74b38-0e7d-4c45-aa91-31ede066b523",
   "metadata": {},
   "source": [
    "# モデルの重みの保存と読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f284c40-3e7d-4a2f-baa7-3faa954cbe96",
   "metadata": {},
   "source": [
    "- モデルは学習したパラメータを内部に状態辞書(state_dict)として保持している\n",
    "- モデルパラメータの値は`torch.save`を使用することで保存することができる\n",
    "- **推論前にはDropoutやBatchNormをevaluationモードに切り替えるため, 推論前にはmodel.eval()を実行する必要がある**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a2bffa-c2ef-4ba4-a859-e68618785ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e72c17-b100-43c6-b645-cd5e7c5f66c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "\n",
    "# 推論モードへの切り替え\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a46f81-4a45-41b8-a6d1-1d1fb88408a9",
   "metadata": {},
   "source": [
    "## モデルの形ごと保存・読み込む方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1084a3-997b-4e60-ab9c-13101e7f8501",
   "metadata": {},
   "source": [
    "- モデルの重みをロードする場合, 先にモデルのインスタンスを用意しておかなければならない\n",
    "- モデルクラスの構造も一緒に保持したい場合、`torch.load()`を用いることでモデルインスタンスを得ることができる\n",
    "  - ただしその場合は, `model.state_dict()`ではなく, モデルインスタンス自体を`torch.save()`に指定しなければならない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f1a829b-1750-40e5-ac1a-375589f157d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "model = torch.load('model.pth')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997302c-96fa-454a-8f27-d2170ed5b6b5",
   "metadata": {},
   "source": [
    "## ONNX形式でのモデル出力\n",
    "\n",
    "- ONNX形式でモデルを保存するには`torch.onnx.export()`を使用する\n",
    "- PyTorchの計算グラフは動的に生成されるため, 出力を行うには, 計算グラフを実行しておく必要がある\n",
    "  - すなわち, テスト用の適切なテンソルサイズの入力変数を用意して, それをモデルで推論しておく必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "319e3935-4040-4466-86c9-8be5aa81dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像のダミーとして, 同じ形状のゼロ行列を作成\n",
    "input_image = torch.zeros((1, 3, 244, 244))\n",
    "onnx.export(model, input_image, 'model.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1.7",
   "language": "python",
   "name": "pt1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
