{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67101c6-bf4f-4647-a830-a959a62e6efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/y-katayama/notebooks', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/y-katayama/venv/pt1.7/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# importディレクトリの追加\n",
    "# sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "print(sys.path)\n",
    "\n",
    "# プロキシの設定\n",
    "# os.environ['HTTP_PROXY'] = ''\n",
    "# os.environ['HTTPS_PROXY'] = ''\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b221e63-1a66-4da5-8964-2dedabf6108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  6 10:41:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   32C    P8    17W / 184W |     47MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 40%   30C    P8    13W / 184W |      5MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1986      G   /usr/lib/xorg/Xorg                 45MiB |\n",
      "|    1   N/A  N/A      1986      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8559762-ee4a-4c55-a9c6-d89f1539664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eec6999-74c5-4772-8615-de06c1ee1f05",
   "metadata": {},
   "source": [
    "## テンソルの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a16b2013-6564-4cd7-9786-c66e2ff487b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor([[1, 2],\n",
      "        [3, 4]])}\n",
      "tensor([[4, 3],\n",
      "        [2, 1]])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.2309, 0.6264],\n",
      "        [0.9460, 0.6480]])\n"
     ]
    }
   ],
   "source": [
    "# リストから直接テンソルを作る\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print({x_data})\n",
    "\n",
    "# Numpy Arrayからテンソルを作る\n",
    "np_array = np.array([[4,3], [2,1]])\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "# x_dataの形状を維持してテンソルを作る\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(x_ones)\n",
    "\n",
    "# x_dataのdatatypeを上書き更新する\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38741cc-c3b7-4ee8-8f4b-aa95b83f6533",
   "metadata": {},
   "source": [
    "# ランダム値や定数テンソル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06458184-7e0d-4fa6-b789-b57d100f42b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_tensor: tensor([[0.6031, 0.0320, 0.6998],\n",
      "        [0.3789, 0.0235, 0.1074]])\n",
      "ones_tensor: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "zeros_tensor: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f'rand_tensor: {rand_tensor}')\n",
    "print(f'ones_tensor: {ones_tensor}')\n",
    "print(f'zeros_tensor: {zeros_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f233e5-9080-4bef-a96e-e8b55e41be85",
   "metadata": {},
   "source": [
    "# テンソルの属性\n",
    "\n",
    "- テンソルは属性変数として, 以下を保持している\n",
    "  - 形状(shape)\n",
    "  - データ型(dtype)\n",
    "  - 保存されているデバイス(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48f0b292-ab82-442f-a75d-f0cb2448b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f54177-5c42-49c1-8293-865ef0b63bf4",
   "metadata": {},
   "source": [
    "# テンソルの操作\n",
    "\n",
    "- テンソルはdefaultではCPU上にt区られる\n",
    "- テンソルは`.to()`を使用して, 任意のデバイスに移動させることができる\n",
    "- 大きなテンソルをデバイス間でコピーすると, 時間とメモリ面でのコストがかかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6a8299f-46f3-43e9-b132-8b04281dd148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7189, 0.4346, 0.8713, 0.8511],\n",
      "        [0.8774, 0.0375, 0.6056, 0.8145],\n",
      "        [0.6037, 0.2918, 0.8418, 0.8067]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')\n",
    "\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed68590-1ea1-46b3-9798-ac19d61c9515",
   "metadata": {},
   "source": [
    "## Numpy-likeなindexingとslicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f6247b4-a919-4930-be90-3cb5eaa58602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first row: tensor([1., 1., 1., 1.])\n",
      "first col: tensor([1., 1., 1., 1.])\n",
      "last col: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "# 1行目のテンソルを表示\n",
    "print(f'first row: {tensor[0]}')\n",
    "\n",
    "# 1列目のテンソルを表示\n",
    "print(f'first col: {tensor[:, 0]}')\n",
    "\n",
    "# 最終列のテンソルを表示\n",
    "print(f'last col: {tensor[..., -1]}')\n",
    "\n",
    "# 2列目に0を代入\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b50918-4685-4147-9c60-8f660a7bd240",
   "metadata": {},
   "source": [
    "## テンソルの結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99be1a69-741e-432a-94b8-d173bbc8e123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.],\n",
      "         [1., 0., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat()は横方向に連結する\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "\n",
    "# torch.stack()は縦方向に連結する\n",
    "t2 = torch.stack([tensor, tensor, tensor], dim=1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b114a44-bc75-44b6-9110-546872372044",
   "metadata": {},
   "source": [
    "## 算術演算\n",
    "\n",
    "- 行列の内積は`@オペレータ`か`matmul()`で求められる\n",
    "- 行列の要素ごとの積(アダマール積)は`*オペレータ`, `mul()`で求められる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f03bf1a-80a6-43ca-84a1-4af7f1a6578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y2: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y3: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "z1: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z2: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z3: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 内積を計算\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "print(f'y1: {y1}')\n",
    "print(f'y2: {y2}')\n",
    "print(f'y3: {y3}')\n",
    "\n",
    "# アダマール積を計算\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "\n",
    "print(f'z1: {z1}')\n",
    "print(f'z2: {z2}')\n",
    "print(f'z3: {z3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8c761-5f99-4050-99c9-dcccba9b64fd",
   "metadata": {},
   "source": [
    "## 1要素のテンソル\n",
    "\n",
    "- 1要素のテンソルは`.item()`を使用して数値型に変換できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f983f820-055e-48cc-8ac8-909594f17ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# item()で数値型変換できる\n",
    "print(tensor)\n",
    "\n",
    "# 全要素の総和 = 12\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba6208-da27-4c3a-b33a-aeaf16f1626d",
   "metadata": {},
   "source": [
    "## インプレース操作\n",
    "\n",
    "- 演算結果をオペランドに格納する操作をインプレースと呼ぶ\n",
    "- インプレース操作はメソッドの接頭辞に`_`が付く\n",
    "  - `x.copy_()`や`x.t_()`等\n",
    "\n",
    "  \n",
    "- インプレース操作はメモリを節約できるが, 演算履歴が失われるため, 微分計算の際に問題となる\n",
    "\n",
    "- **微分を求める場合, インプレース操作は非推奨**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02c3e7-5bfc-4d9c-9a9c-51ea4dc2d8d3",
   "metadata": {},
   "source": [
    "# Numpyとの変換\n",
    "\n",
    "- torch.Tensorは`.numpy()`を使用してNumpy配列に変換できる\n",
    "- 変換したオブジェクトは同じメモリを共有している\n",
    "    - 元のテンソルが変化するとNumpy側も, 変化が反映される\n",
    "    - これはNumpyからTensorに変換する場合も同じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a06b57c1-6b9e-4b92-95c9-35675e79b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f't: {t}')\n",
    "\n",
    "n = t.numpy()\n",
    "print(f'n: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cec87b9a-c017-4264-84c9-716753cc02f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# 元のテンソルの値を変更\n",
    "t.add_(1)\n",
    "\n",
    "# 変換後のNump\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cc7e4e-36cb-4c3b-adf4-8f3ef7d26dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt1.7",
   "language": "python",
   "name": "pt1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
